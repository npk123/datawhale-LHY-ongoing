1 理解偏差和方差

偏差.

这里的偏指的是 偏离 , 那么它偏离了什么到导致了误差? 潜意识上, 当谈到这个词时, 我们可能会认为它是偏离了某个潜在的 “标准”, 
而这里这个 “标准” 也就是真实情况 (ground truth). 在分类任务中, 这个 “标准” 就是真实标签 (label).

方差.

很多人应该都还记得在统计学中, 一个随机变量的方差描述的是它的离散程度, 也就是该随机变量在其期望值附近的 波动程度 . 

2 学习误差为什么是偏差和方差而产生的，并且推导数学公式

误差为偏差、方差与噪声之和

3 过拟合，欠拟合，分别对应bias和variance什么情况

一般来说，简单的模型会有一个较大的偏差和较小的方差，复杂的模型偏差较小方差较大。

欠拟合：模型不能适配训练样本，有一个很大的偏差。

举个例子：我们可能有本质上是多项式的连续非线性数据，但模型只能表示线性关系。在此情况下，我们向模型提供多少数据不重要，
因为模型根本无法表示数据的基本关系，模型不能适配训练样本，有一个很大的偏差，因此我们需要更复杂的模型。
那么，是不是模型越复杂拟合程度越高越好呢？也不是，因为还有方差。

过拟合：模型很好的适配训练样本，但在测试集上表现很糟，有一个很大的方差。

方差就是指模型过于拟合训练数据，以至于没办法把模型的结果泛化。而泛化正是机器学习要解决的问题，如果一个模型只能对一组特定的数据有效，
换了数据就无效，我们就说这个模型过拟合。这就是模型很好的适配训练样本，但在测试集上表现很糟，有一个很大的方差。

4 学习鞍点，复习上次任务学习的全局最优和局部最优

5 解决办法有哪些

整体思路：首先，要知道偏差和方差是无法完全避免的，只能尽量减少其影响。

    （1）在避免偏差时，需尽量选择正确的模型，一个非线性问题而我们一直用线性模型去解决，那无论如何，高偏差是无法避免的。
    （2）有了正确的模型，我们还要慎重选择数据集的大小，通常数据集越大越好，但大到数据集已经对整体所有数据有了一定的代表性后，再多的数据已经不能提升模型了，反而会带来计算量的增加。而训练数据太小一定是不好的，这会带来过拟合，模型复杂度太高，方差很大，不同数据集训练出来的模型变化非常大。
    （3）最后，要选择合适的模型复杂度，复杂度高的模型通常对训练数据有很好的拟合能力。

针对偏差和方差的思路：
偏差：实际上也可以称为避免欠拟合。
1、寻找更好的特征 -- 具有代表性。
2、用更多的特征 -- 增大输入向量的维度。（增加模型复杂度）
方差：避免过拟合
1、增大数据集合 -- 使用更多的数据，减少数据扰动所造成的影响
2、减少数据特征 -- 减少数据维度，减少模型复杂度
3、正则化方法
4、交叉验证法

梯度下降

学习Mini-Batch与SGD


学习Batch与Mini-Batch，SGD梯度下降的区别

如何根据样本大小选择哪个梯度下降(批量梯度下降，Mini-Batch）

写出SGD和Mini-Batch的代码

学习交叉验证

学习归一化 

学习回归模型评价指标
